# Options
1. Ceph internal benchmark for Ceph clusters
2. IOzone on mounted ceph stores

# Ceph benchmark
## benchmark disk with dd
- dd if=/dev/zero of=here bs=1G count=1 oflag=direct
- output:
  - 记录了1+0 的读入
  - 记录了1+0 的写出
  - 1073741824字节(1.1 GB)已复制，5.03876 秒，213 MB/秒

## benchmark network with iperf
- iperf -c <store IP >

## benchmark ceph with rados

Use rados to benchmark ceph. rados is included in ceph deployment.

- create a new pool:
  - ceph osd pool create scbench 100 100

- perform write benchmarking on scbench:
  - rados bench -p scbench 10 write --no-cleanup

- 2 types of read benchmarks are available: seqential and random:
  - rados bench -p scbench 10 seq
  - rados bench -p scbench 10 rand

## Benchmark A CEPH BLOCK DEVICE
Ceph already includes the rbd bench command, but you can also use the popular I/O benchmarking tool fio, which now comes with built in support for RADOS block devices.

## BENCHMARK A CEPH OBJECT GATEWAY
swift-bench benchmarking tool is included with OpenStack Swift, which tests the performance of your Ceph cluster by simulating client PUT and GET requests and measuring their performance

# IOzone install

## Download the latest build of IOzone
   wget http://www.iozone.org/src/current/iozone-3-484.i386.rpm

## Install IOzone rpm
   sudo rpm -ivh iozone-3-484.i386.rpm

## Check IOzone install
   ls /opt/iozone/bin/

# Run IOzone
   /opt/iozone/bin/iozone -R -l 5 -u 5 -r 4k -s 100m -F /home | tee -a /tmp/iozone_results.txt &

# References
- https://www.cyberciti.biz/tips/linux-filesystem-benchmarking-with-iozone.html
- https://tracker.ceph.com/projects/ceph/wiki/Benchmark_Ceph_Cluster_Performance
